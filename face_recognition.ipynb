{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition as fr\n",
    "import numpy\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the test images and store the names of the people in a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"G:\\openCV_project\\Image Basics\"\n",
    "images=[]\n",
    "classNames=[]\n",
    "mylist=os.listdir(path)\n",
    "print(mylist)\n",
    "\n",
    "for cl in mylist:\n",
    "    curImg=cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(cl)[0])\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function findEncodings() is written to find the encodings of the images using using face_encodings() which is a function of face_recognition library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEncodings(images):\n",
    "    encodeList=[]\n",
    "    for img in images:\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        encode=fr.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function markAttendance() is written to save the name and joining time of the person in a CSV file. If a name is present in the file, that name would not be saved again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markAttendance(name):\n",
    "    with open(r\"G:\\openCV_project\\attendance.csv\",\"r+\") as f:\n",
    "        myDataList=f.readlines()\n",
    "        nameList=[]\n",
    "        print(myDataList)\n",
    "        for line in myDataList:\n",
    "            entry=line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now=datetime.now()\n",
    "            dtString=now.strftime(\"%H:%M:%S\")\n",
    "            f.writelines(f'\\n{name},{dtString}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling findEncodings() to determine the face encoding of the images present in the image folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodeListKnown=findEncodings(images)\n",
    "print(\"encoding completes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we will execute the face recognition function on the faces taken through live webcam feed and record the encodings of those recognised images.\n",
    "\n",
    "#### These encodings will be matched with the recorded encodings of the images present in the folder and distance is find between the encodings using face_distance() present in face_recognition module. The image with lowest distance would be the best match and that name will be displayed over the image of live webcam feed. The name and current time of the matched image is saved in CSV file using markAttendance()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    success,img=cap.read()\n",
    "    #reduce size of image to speed up the process\n",
    "    imgS=cv2.resize(img,(0,0),None,0.25,0.25)\n",
    "    imgS=cv2.cvtColor(imgS,cv2.COLOR_BGR2RGB)\n",
    "    facesCurFrame=fr.face_locations(imgS)\n",
    "    encodesCurFrame=fr.face_encodings(imgS,facesCurFrame)\n",
    "    \n",
    "    for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
    "        matches=fr.compare_faces(encodeListKnown,encodeFace)\n",
    "        faceDis=fr.face_distance(encodeListKnown,encodeFace)\n",
    "        print(faceDis)\n",
    "        \n",
    "        #find the best match with lowest distance\n",
    "        matchIndex=numpy.argmin(faceDis)\n",
    "        if matches[matchIndex]:\n",
    "            name=classNames[matchIndex].upper()\n",
    "            print(name)\n",
    "            \n",
    "            #putting the text and rectangle on the image recognised in webcam feed\n",
    "            y1,x2,y2,x1=faceLoc\n",
    "            y1,x2,y2,x1=y1*4,x2*4,y2*4,x1*4\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
    "            cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "            markAttendance(name)\n",
    "            \n",
    "    cv2.imshow(\"webcam\",img)\n",
    "    if cv2.waitKey()==ord(\"s\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
